# -*- coding: utf-8 -*-
"""scms_project1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NJ7jh0hXonc9z_fwk1DjAtMbxrXZqnA9
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
#libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn import tree 
from sklearn.model_selection import train_test_split
from scipy import stats
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
import statsmodels.api as sm

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split,cross_val_score,KFold,GridSearchCV
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import RobustScaler


from subprocess import check_output

# use seaborn plotting defaults
import seaborn as sns; sns.set()

# import warnings
# warnings.filterwarnings('ignore')

dataset = pd.read_csv('/content/drive/MyDrive/SCMS_Delivery_History_Dataset.csv')

new_scmsp = dataset.copy()
#convert the datatype object to numeric
new_scmsp['Weight (Kilograms)'] = pd.to_numeric(new_scmsp['Weight (Kilograms)'],errors='coerce')
new_scmsp['Freight Cost (USD)'] = pd.to_numeric(new_scmsp['Freight Cost (USD)'],errors='coerce')

missing_values =new_scmsp[new_scmsp['Shipment Mode'].isna()].index
new_scmsp= new_scmsp.drop(missing_values,axis=0).reset_index(drop = True)
new_scmsp['Dosage'] = new_scmsp['Dosage'].fillna(new_scmsp['Dosage'].mode()[0])
new_scmsp['Line Item Insurance (USD)'] =new_scmsp['Line Item Insurance (USD)'].fillna(new_scmsp['Line Item Insurance (USD)'].mean())

    # fill the missing values
new_scmsp['Weight (Kilograms)'] = new_scmsp['Weight (Kilograms)'].fillna(new_scmsp['Weight (Kilograms)'].mean())
new_scmsp['Freight Cost (USD)'] = new_scmsp['Freight Cost (USD)'].fillna(new_scmsp['Freight Cost (USD)'].mean())
#new_scmsp.isna().sum()

# Drop the columns not need longer
new_scmsp = new_scmsp.drop(['ID','PQ First Sent to Client Date', 'PO Sent to Vendor Date'],axis = 1)
new_scmsp.shape

num_data = new_scmsp.select_dtypes(np.number)
print(num_data.columns)
print('The number of numerical columns:\t',len(num_data.columns))

categorical_data = new_scmsp.select_dtypes('object')
print(categorical_data.columns)
print('The number of numerical columns:\t',len(categorical_data.columns))

# Pairplot 
sns.pairplot(num_data,diag_kind='kde')

## testing new variables by checking their correlation w.r.t. MPG
new_scmsp['Price_Shipment'] = new_scmsp['Freight Cost (USD)'] + new_scmsp['Line Item Insurance (USD)']

new_scmsp.shape
new_scmsp.info()

le = LabelEncoder()
for i in categorical_data:
  new_scmsp[i] =le.fit_transform(new_scmsp[i].astype(str))

X = new_scmsp.drop(['Price_Shipment'],axis= 1)
y = new_scmsp[['Price_Shipment']]
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.22)

#fit random forest
random_forest = RandomForestRegressor(n_estimators=100)
random_forest.fit(X_train,y_train)
Y_prediction = random_forest.predict(X_test)

random_forest.score(X_train,y_train)
acc_random_forest = round(random_forest.score(X_train,y_train) * 100, 2)


print("Random Forest Accuracy : ",acc_random_forest)

acc_random_forest_testdata = round(random_forest.score(X_test, y_test) * 100, 2)
print('Test data Random forest Accuacy :',acc_random_forest_testdata)

model=RandomForestRegressor(n_estimators=150,max_features=5,min_samples_leaf=25)
cv_res=cross_val_score(model,X_train,y_train,cv=10)
print(cv_res.mean()*100)

from sklearn.metrics import mean_squared_error
mse1 = mean_squared_error(y_test,Y_prediction)
print(mse1)

"""# **Feature Selection by correlation Matrix**"""

corr_matrix =new_scmsp.corr()
corr_matrix['Price_Shipment'].sort_values(ascending=False)

le = LabelEncoder()
for i in categorical_data:
  new_scmsp[i] =le.fit_transform(new_scmsp[i].astype(str))

corr_matrix =new_scmsp.corr()
corr_matrix['Price_Shipment'].sort_values(ascending=False)

"""# **Feature Selction by Lasso Regression**"""

from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectFromModel

feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function
feature_sel_model.fit(X_train, y_train)

feature_sel_model.get_support()


# to visualise al the columns in the dataframe
pd.pandas.set_option('display.max_columns', None)

feature_sel_model.get_support()
# let's print the number of total and selected features

# this is how we can make a list of the selected features
selected_feat = X_train.columns[(feature_sel_model.get_support())]

print('selected features: {}'.format(selected_feat))

# let's print some stats
print('total features: {}'.format((X_train.shape[1])))
print('selected features: {}'.format(len(selected_feat)))
#print('features with coefficients shrank to zero: {}'.format(np.sum(sel_.estimator_.coef_ == 0)))

"""# ***Select the Feature by Forword Selection***"""

target=new_scmsp[['Price_Shipment']]

def forward_selection(new_scmsp, target, significance_level=0.05):
    initial_features =new_scmsp.columns.tolist()
    best_features = []
    while (len(initial_features)>0):
        remaining_features = list(set(initial_features)-set(best_features))
        new_pval = pd.Series(index=remaining_features)
        for new_column in remaining_features:
          model = sm.OLS(target, sm.add_constant(new_scmsp[best_features+[new_column]])).fit()
          new_pval[new_column] = model.pvalues[new_column]
        min_p_value = new_pval.min()
        if(min_p_value<significance_level):
            best_features.append(new_pval.idxmin())
        else:
            break
    return best_features


print(forward_selection(X_train,y_train))
print('Total Feature is ',len(forward_selection(X_train,y_train)))

train_x2  =new_scmsp[['Freight Cost (USD)', 'Line Item Value', 'Line Item Insurance (USD)', 
 'Delivery Recorded Date', 'Weight (Kilograms)', 'Line Item Quantity', 
 'Delivered to Client Date', 'PO / SO #', 'ASN/DN #', 'Brand', 'Project Code']]

#train_y2 = new_scmsp['Price_Shipment']

train_y2 = new_scmsp[['Price_Shipment']]

"""# **Train The model**"""

train_x,test_x,train_y,test_y = train_test_split(train_x2,train_y2, test_size = 0.33)

#fit decision tree
decision_tree = DecisionTreeRegressor()
decision_tree.fit(train_x,train_y)
Y_pred = decision_tree.predict(test_x)
acc_decision_tree = round(decision_tree.score(train_x,train_y) * 100, 2)

print('Decision tree Accuacy :',acc_decision_tree)
#print("Random Forest Accuracy : ",acc_random_forest)
acc_testdata = round(decision_tree.score(test_x, test_y) * 100, 2)
print('Test data Decision tree Accuacy :',acc_testdata)

#fit random forest
random_forest = RandomForestRegressor(n_estimators=100)
random_forest.fit(train_x,train_y)
Y_prediction = random_forest.predict(test_x)

random_forest.score(train_x,train_y)
acc_random_forest = round(random_forest.score(train_x,train_y) * 100, 2)


print("Random Forest Accuracy : ",acc_random_forest)

acc_random_forest_testdata = round(random_forest.score(test_x, test_y) * 100, 2)
print('Test data Random forest Accuacy :',acc_random_forest_testdata)

model=RandomForestRegressor(n_estimators=150,max_features=5,min_samples_leaf=25)
cv_res=cross_val_score(model,train_x,train_y,cv=10)

cv_res1 = cross_val_score(model,test_x,test_y, cv = 10)
print(cv_res.mean()*100)
print(cv_res1.mean()*100)

random_forest = RandomForestRegressor(n_estimators=100)
random_forest.fit(train_x,train_y)
Y_prediction = random_forest.predict(test_x)

random_forest.score(train_x,train_y)
acc_random_forest = round(random_forest.score(train_x,train_y) * 100, 2)


print("Random Forest Accuracy : ",acc_random_forest)

acc_random_forest_testdata = round(random_forest.score(test_x, test_y) * 100, 2)
print('Test data Random forest Accuacy :',acc_random_forest_testdata)